{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d429ef2e",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-06-26T14:58:48.934300Z",
     "iopub.status.busy": "2022-06-26T14:58:48.933652Z",
     "iopub.status.idle": "2022-06-26T14:58:56.652231Z",
     "shell.execute_reply": "2022-06-26T14:58:56.651101Z"
    },
    "papermill": {
     "duration": 7.730185,
     "end_time": "2022-06-26T14:58:56.654635",
     "exception": false,
     "start_time": "2022-06-26T14:58:48.924450",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import csv\n",
    "import random\n",
    "import pickle\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from scipy.ndimage.measurements import label\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, array_to_img, img_to_array\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f54afc",
   "metadata": {
    "papermill": {
     "duration": 0.00507,
     "end_time": "2022-06-26T14:58:56.665489",
     "exception": false,
     "start_time": "2022-06-26T14:58:56.660419",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7507f0f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T14:58:56.677314Z",
     "iopub.status.busy": "2022-06-26T14:58:56.676742Z",
     "iopub.status.idle": "2022-06-26T14:58:56.691409Z",
     "shell.execute_reply": "2022-06-26T14:58:56.690536Z"
    },
    "papermill": {
     "duration": 0.022721,
     "end_time": "2022-06-26T14:58:56.693216",
     "exception": false,
     "start_time": "2022-06-26T14:58:56.670495",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GlaucomaDataset(Dataset):\n",
    "\n",
    "    def __init__(self, root_dir, split='train', output_size=(256,256)):\n",
    "        self.output_size = output_size\n",
    "        self.root_dir = root_dir\n",
    "        self.split = split\n",
    "        self.images = []\n",
    "        self.segs = []\n",
    "        # Load data index\n",
    "        for direct in self.root_dir:\n",
    "            self.image_filenames = []\n",
    "            for path in os.listdir(os.path.join(direct, \"Images_Square\")):\n",
    "                if(not path.startswith('.')):\n",
    "                    self.image_filenames.append(path)\n",
    "\n",
    "\n",
    "            for k in range(len(self.image_filenames)):\n",
    "                print('Loading {} image {}/{}...'.format(split, k, len(self.image_filenames)), end='\\r')\n",
    "                img_name = os.path.join(direct, \"Images_Square\", self.image_filenames[k])\n",
    "                #img = remove_nerves(np.array(Image.open(img_name).convert('RGB'))).astype(np.float32)\n",
    "                img = np.array(Image.open(img_name).convert('RGB'))\n",
    "                img = transforms.functional.to_tensor(img)\n",
    "                img = transforms.functional.resize(img, output_size, interpolation=Image.BILINEAR)\n",
    "                self.images.append(img)\n",
    "            if split != 'test':\n",
    "                for k in range(len(self.image_filenames)):\n",
    "                    print('Loading {} segmentation {}/{}...'.format(split, k, len(self.image_filenames)), end='\\r')\n",
    "                    seg_name = os.path.join(direct, \"Masks_Square\", self.image_filenames[k][:-3] + \"png\")\n",
    "                    mask = np.array(Image.open(seg_name, mode='r'))\n",
    "                    od = (mask==1.).astype(np.float32)\n",
    "                    oc = (mask==2.).astype(np.float32)\n",
    "                    od = torch.from_numpy(od[None,:,:])\n",
    "                    oc = torch.from_numpy(oc[None,:,:])\n",
    "                    od = transforms.functional.resize(od, output_size, interpolation=Image.NEAREST)\n",
    "                    oc = transforms.functional.resize(oc, output_size, interpolation=Image.NEAREST)\n",
    "                    self.segs.append(torch.cat([od, oc], dim=0))\n",
    "\n",
    "            print('Succesfully loaded {} dataset.'.format(split) + ' '*50)\n",
    "            \n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx]\n",
    "        if self.split == 'test':\n",
    "            return img\n",
    "        else:\n",
    "            seg = self.segs[idx]\n",
    "            return img, seg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0606e7",
   "metadata": {
    "papermill": {
     "duration": 0.004718,
     "end_time": "2022-06-26T14:58:56.702926",
     "exception": false,
     "start_time": "2022-06-26T14:58:56.698208",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f8d8aae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T14:58:56.714137Z",
     "iopub.status.busy": "2022-06-26T14:58:56.713842Z",
     "iopub.status.idle": "2022-06-26T14:58:56.720454Z",
     "shell.execute_reply": "2022-06-26T14:58:56.719564Z"
    },
    "papermill": {
     "duration": 0.014311,
     "end_time": "2022-06-26T14:58:56.722352",
     "exception": false,
     "start_time": "2022-06-26T14:58:56.708041",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_nerves(image):\n",
    "    img = array_to_img(image)\n",
    "    \n",
    "    img = cv2.cvtColor(np.array(img), cv2.COLOR_BGR2RGB)\n",
    "    # convert image to grayScale\n",
    "    grayScale = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "   \n",
    "    # kernel for morphologyEx\n",
    "    kernel = cv2.getStructuringElement(1,(17,17))\n",
    "   \n",
    "    # apply MORPH_BLACKHAT to grayScale image\n",
    "    blackhat = cv2.morphologyEx(grayScale, cv2.MORPH_BLACKHAT, kernel)\n",
    "  \n",
    "    # apply thresholding to blackhat\n",
    "    _,threshold = cv2.threshold(blackhat,10,255,cv2.THRESH_BINARY)\n",
    "\n",
    "    # inpaint with original image and threshold image\n",
    "    final_image = cv2.inpaint(img,threshold,1,cv2.INPAINT_TELEA)\n",
    "    final_image = cv2.cvtColor(final_image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    return final_image.astype(np.float64)/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5830a4f",
   "metadata": {
    "papermill": {
     "duration": 0.004797,
     "end_time": "2022-06-26T14:58:56.732064",
     "exception": false,
     "start_time": "2022-06-26T14:58:56.727267",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd2cdc65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T14:58:56.743504Z",
     "iopub.status.busy": "2022-06-26T14:58:56.742777Z",
     "iopub.status.idle": "2022-06-26T14:58:56.754192Z",
     "shell.execute_reply": "2022-06-26T14:58:56.753397Z"
    },
    "papermill": {
     "duration": 0.018986,
     "end_time": "2022-06-26T14:58:56.756010",
     "exception": false,
     "start_time": "2022-06-26T14:58:56.737024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "EPS = 1e-7\n",
    "\n",
    "def compute_dice_coef(input, target):\n",
    "    '''\n",
    "    Compute dice score metric.\n",
    "    '''\n",
    "    batch_size = input.shape[0]\n",
    "    return sum([dice_coef_sample(input[k,:,:], target[k,:,:]) for k in range(batch_size)])/batch_size\n",
    "\n",
    "def dice_coef_sample(input, target):\n",
    "    iflat = input.contiguous().view(-1)\n",
    "    tflat = target.contiguous().view(-1)\n",
    "    intersection = (iflat * tflat).sum()\n",
    "    return (2. * intersection) / (iflat.sum() + tflat.sum())\n",
    "\n",
    "\n",
    "def vertical_diameter(binary_segmentation):\n",
    "    '''\n",
    "    Get the vertical diameter from a binary segmentation.\n",
    "    The vertical diameter is defined as the \"fattest\" area of the binary_segmentation parameter.\n",
    "    '''\n",
    "\n",
    "    # get the sum of the pixels in the vertical axis\n",
    "    vertical_axis_diameter = np.sum(binary_segmentation, axis=1)\n",
    "\n",
    "    # pick the maximum value\n",
    "    diameter = np.max(vertical_axis_diameter, axis=1)\n",
    "\n",
    "    # return it\n",
    "    return diameter\n",
    "\n",
    "\n",
    "\n",
    "def vertical_cup_to_disc_ratio(od, oc):\n",
    "    '''\n",
    "    Compute the vertical cup-to-disc ratio from a given labelling map.\n",
    "    '''\n",
    "    # compute the cup diameter\n",
    "    cup_diameter = vertical_diameter(oc)\n",
    "    # compute the disc diameter\n",
    "    disc_diameter = vertical_diameter(od)\n",
    "\n",
    "    return cup_diameter / (disc_diameter + EPS)\n",
    "\n",
    "def compute_vCDR_error(pred_od, pred_oc, gt_od, gt_oc):\n",
    "    '''\n",
    "    Compute vCDR prediction error, along with predicted vCDR and ground truth vCDR.\n",
    "    '''\n",
    "    pred_vCDR = vertical_cup_to_disc_ratio(pred_od, pred_oc)\n",
    "    gt_vCDR = vertical_cup_to_disc_ratio(gt_od, gt_oc)\n",
    "    vCDR_err = np.mean(np.abs(gt_vCDR - pred_vCDR))\n",
    "    return vCDR_err, pred_vCDR, gt_vCDR\n",
    "\n",
    "\n",
    "def classif_eval(classif_preds, classif_gts):\n",
    "    '''\n",
    "    Compute AUC classification score.\n",
    "    '''\n",
    "    auc = roc_auc_score(classif_gts, classif_preds)\n",
    "    return auc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b88373",
   "metadata": {
    "papermill": {
     "duration": 0.004903,
     "end_time": "2022-06-26T14:58:56.765943",
     "exception": false,
     "start_time": "2022-06-26T14:58:56.761040",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Post Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2c71b1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T14:58:56.776941Z",
     "iopub.status.busy": "2022-06-26T14:58:56.776666Z",
     "iopub.status.idle": "2022-06-26T14:58:56.783141Z",
     "shell.execute_reply": "2022-06-26T14:58:56.782240Z"
    },
    "papermill": {
     "duration": 0.014066,
     "end_time": "2022-06-26T14:58:56.784999",
     "exception": false,
     "start_time": "2022-06-26T14:58:56.770933",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def refine_seg(pred):\n",
    "    '''\n",
    "    Only retain the biggest connected component of a segmentation map.\n",
    "    '''\n",
    "    np_pred = pred.numpy()\n",
    "        \n",
    "    largest_ccs = []\n",
    "    for i in range(np_pred.shape[0]):\n",
    "        labeled, ncomponents = label(np_pred[i,:,:])\n",
    "        bincounts = np.bincount(labeled.flat)[1:]\n",
    "        if len(bincounts) == 0:\n",
    "            largest_cc = labeled == 0\n",
    "        else:\n",
    "            largest_cc = labeled == np.argmax(bincounts)+1\n",
    "        largest_cc = torch.tensor(largest_cc, dtype=torch.float32)\n",
    "        largest_ccs.append(largest_cc)\n",
    "    largest_ccs = torch.stack(largest_ccs)\n",
    "    \n",
    "    return largest_ccs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210b034e",
   "metadata": {
    "papermill": {
     "duration": 0.004885,
     "end_time": "2022-06-26T14:58:56.794975",
     "exception": false,
     "start_time": "2022-06-26T14:58:56.790090",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f2899de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T14:58:56.806835Z",
     "iopub.status.busy": "2022-06-26T14:58:56.806556Z",
     "iopub.status.idle": "2022-06-26T14:58:56.828769Z",
     "shell.execute_reply": "2022-06-26T14:58:56.827887Z"
    },
    "papermill": {
     "duration": 0.030664,
     "end_time": "2022-06-26T14:58:56.830766",
     "exception": false,
     "start_time": "2022-06-26T14:58:56.800102",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels=3, n_classes=2):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.epoch = 0\n",
    "\n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        self.down4 = Down(512, 1024)\n",
    "        self.down5 = Down(1024, 2048)\n",
    "        factor = 2 \n",
    "        self.down6 = Down(2048, 4096 // factor)\n",
    "        self.up1 = Up(4096, 2048 // factor)\n",
    "        self.up2 = Up(2048, 1024 // factor)\n",
    "        self.up3 = Up(1024, 512 // factor)\n",
    "        self.up4 = Up(512, 256 // factor)\n",
    "        self.up5 = Up(256, 128 // factor)\n",
    "        self.up6 = Up(128, 64)\n",
    "        self.output_layer = OutConv(64, n_classes)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x6 = self.down5(x5)\n",
    "        x7 = self.down6(x6)\n",
    "        out = self.up1(x7, x6)\n",
    "        out = self.up2(out, x5)\n",
    "        out = self.up3(out, x4)\n",
    "        out = self.up4(out, x3)\n",
    "        out = self.up5(out, x2)\n",
    "        out = self.up6(out, x1)\n",
    "        out = self.output_layer(out)\n",
    "        out = torch.sigmoid(out)\n",
    "        return out\n",
    "\n",
    "    \n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "            \n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "            \n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        # Use the normal convolutions to reduce the number of channels\n",
    "        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "        \n",
    "\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "        \n",
    "\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    '''\n",
    "    Simple convolution.\n",
    "    '''\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd35ce7d",
   "metadata": {
    "papermill": {
     "duration": 0.00492,
     "end_time": "2022-06-26T14:58:56.840771",
     "exception": false,
     "start_time": "2022-06-26T14:58:56.835851",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cee9e62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T14:58:56.852078Z",
     "iopub.status.busy": "2022-06-26T14:58:56.851806Z",
     "iopub.status.idle": "2022-06-26T14:58:56.856414Z",
     "shell.execute_reply": "2022-06-26T14:58:56.855482Z"
    },
    "papermill": {
     "duration": 0.012342,
     "end_time": "2022-06-26T14:58:56.858259",
     "exception": false,
     "start_time": "2022-06-26T14:58:56.845917",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "root_dirs = [ \"../input/glaucoma-datasets/ORIGA\",\"../input/glaucoma-datasets/G1020\"]\n",
    "val_dir = [ \"../input/glaucoma-datasets/REFUGE\"]\n",
    "lr = 1e-4\n",
    "batch_size = 8\n",
    "num_workers = 8\n",
    "total_epoch = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363f4284",
   "metadata": {
    "papermill": {
     "duration": 0.00497,
     "end_time": "2022-06-26T14:58:56.868313",
     "exception": false,
     "start_time": "2022-06-26T14:58:56.863343",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2461cb2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T14:58:56.879641Z",
     "iopub.status.busy": "2022-06-26T14:58:56.879399Z",
     "iopub.status.idle": "2022-06-26T15:03:14.038686Z",
     "shell.execute_reply": "2022-06-26T15:03:14.037200Z"
    },
    "papermill": {
     "duration": 257.169612,
     "end_time": "2022-06-26T15:03:14.043067",
     "exception": false,
     "start_time": "2022-06-26T14:58:56.873455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train image 13/650...\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:23: DeprecationWarning: BILINEAR is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BILINEAR instead.\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/functional.py:424: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train segmentation 13/650...\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:34: DeprecationWarning: NEAREST is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.NEAREST or Dither.NONE instead.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:35: DeprecationWarning: NEAREST is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.NEAREST or Dither.NONE instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succesfully loaded train dataset.                                                  \n",
      "Succesfully loaded train dataset.                                                  \n",
      "Succesfully loaded val dataset.                                                  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    }
   ],
   "source": [
    "train_set = GlaucomaDataset(root_dirs, \n",
    "                          split='train')\n",
    "\n",
    "val_set = GlaucomaDataset(val_dir, \n",
    "                        split='val')\n",
    "\n",
    "train_loader = DataLoader(train_set, \n",
    "                          batch_size=batch_size, \n",
    "                          shuffle=True, \n",
    "                          num_workers=num_workers,\n",
    "                          pin_memory=True,\n",
    "                         )\n",
    "val_loader = DataLoader(val_set, \n",
    "                        batch_size=batch_size, \n",
    "                        shuffle=False, \n",
    "                        num_workers=num_workers,\n",
    "                        pin_memory=True,\n",
    "                        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecef8569",
   "metadata": {
    "papermill": {
     "duration": 0.067089,
     "end_time": "2022-06-26T15:03:14.176436",
     "exception": false,
     "start_time": "2022-06-26T15:03:14.109347",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Init Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31699ca3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T15:03:14.306834Z",
     "iopub.status.busy": "2022-06-26T15:03:14.306491Z",
     "iopub.status.idle": "2022-06-26T15:03:21.908328Z",
     "shell.execute_reply": "2022-06-26T15:03:21.907338Z"
    },
    "papermill": {
     "duration": 7.670217,
     "end_time": "2022-06-26T15:03:21.911292",
     "exception": false,
     "start_time": "2022-06-26T15:03:14.241075",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Device\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "# Network\n",
    "model = UNet(n_channels=3, n_classes=2).to(device)\n",
    "\n",
    "# Loss\n",
    "seg_loss = torch.nn.BCELoss(reduction='mean')\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "#optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d34bd54",
   "metadata": {
    "papermill": {
     "duration": 0.065905,
     "end_time": "2022-06-26T15:03:22.042098",
     "exception": false,
     "start_time": "2022-06-26T15:03:21.976193",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d584657b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T15:03:22.172820Z",
     "iopub.status.busy": "2022-06-26T15:03:22.172478Z",
     "iopub.status.idle": "2022-06-26T16:22:20.241388Z",
     "shell.execute_reply": "2022-06-26T16:22:20.238737Z"
    },
    "papermill": {
     "duration": 4738.137169,
     "end_time": "2022-06-26T16:22:20.244032",
     "exception": false,
     "start_time": "2022-06-26T15:03:22.106863",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION epoch 1                                                  \n",
      "LOSSES: 0.4995 (train), 0.3994 (val)\n",
      "OD segmentation (Dice Score): 0.3531 (train), 0.5370 (val)\n",
      "OC segmentation (Dice Score): 0.1653 (train), 0.1160 (val)\n",
      "vCDR error: 8.6617 (train), 5.7519 (val)\n",
      "Best validation AUC reached. Saved model weights.\n",
      "__________________________________________________\n",
      "VALIDATION epoch 2                                                  \n",
      "LOSSES: 0.3392 (train), 0.2836 (val)\n",
      "OD segmentation (Dice Score): 0.5450 (train), 0.6851 (val)\n",
      "OC segmentation (Dice Score): 0.3129 (train), 0.6201 (val)\n",
      "vCDR error: 3.9439 (train), 1.9759 (val)\n",
      "Best validation AUC reached. Saved model weights.\n",
      "__________________________________________________\n",
      "VALIDATION epoch 3                                                  \n",
      "LOSSES: 0.2276 (train), 0.2009 (val)\n",
      "OD segmentation (Dice Score): 0.6889 (train), 0.7708 (val)\n",
      "OC segmentation (Dice Score): 0.5606 (train), 0.7326 (val)\n",
      "vCDR error: 1.1119 (train), 0.3612 (val)\n",
      "Best validation AUC reached. Saved model weights.\n",
      "__________________________________________________\n",
      "VALIDATION epoch 4                                                  \n",
      "LOSSES: 0.1568 (train), 0.1576 (val)\n",
      "OD segmentation (Dice Score): 0.7143 (train), 0.7459 (val)\n",
      "OC segmentation (Dice Score): 0.5964 (train), 0.7713 (val)\n",
      "vCDR error: 1.1536 (train), 0.1621 (val)\n",
      "Best validation AUC reached. Saved model weights.\n",
      "__________________________________________________\n",
      "VALIDATION epoch 5                                                  \n",
      "LOSSES: 0.1106 (train), 0.1067 (val)\n",
      "OD segmentation (Dice Score): 0.7425 (train), 0.7667 (val)\n",
      "OC segmentation (Dice Score): 0.6068 (train), 0.7499 (val)\n",
      "vCDR error: 0.8591 (train), 0.2202 (val)\n",
      "__________________________________________________\n",
      "VALIDATION epoch 6                                                  \n",
      "LOSSES: 0.0792 (train), 0.0680 (val)\n",
      "OD segmentation (Dice Score): 0.7625 (train), 0.7374 (val)\n",
      "OC segmentation (Dice Score): 0.6251 (train), 0.7435 (val)\n",
      "vCDR error: 0.7833 (train), 0.3436 (val)\n",
      "__________________________________________________\n",
      "VALIDATION epoch 7                                                  \n",
      "LOSSES: 0.0577 (train), 0.0519 (val)\n",
      "OD segmentation (Dice Score): 0.7798 (train), 0.7981 (val)\n",
      "OC segmentation (Dice Score): 0.6356 (train), 0.8089 (val)\n",
      "vCDR error: 0.6444 (train), 0.1099 (val)\n",
      "Best validation AUC reached. Saved model weights.\n",
      "__________________________________________________\n",
      "VALIDATION epoch 8                                                  \n",
      "LOSSES: 0.0445 (train), 0.0424 (val)\n",
      "OD segmentation (Dice Score): 0.7932 (train), 0.6702 (val)\n",
      "OC segmentation (Dice Score): 0.6434 (train), 0.7996 (val)\n",
      "vCDR error: 0.6738 (train), 0.2564 (val)\n",
      "__________________________________________________\n",
      "VALIDATION epoch 9                                                  \n",
      "LOSSES: 0.0356 (train), 0.0324 (val)\n",
      "OD segmentation (Dice Score): 0.8012 (train), 0.8065 (val)\n",
      "OC segmentation (Dice Score): 0.6482 (train), 0.8091 (val)\n",
      "vCDR error: 0.7382 (train), 0.1586 (val)\n",
      "Best validation AUC reached. Saved model weights.\n",
      "__________________________________________________\n",
      "VALIDATION epoch 10                                                  \n",
      "LOSSES: 0.0289 (train), 0.0310 (val)\n",
      "OD segmentation (Dice Score): 0.8188 (train), 0.6857 (val)\n",
      "OC segmentation (Dice Score): 0.6598 (train), 0.7167 (val)\n",
      "vCDR error: 0.7524 (train), 2.2238 (val)\n",
      "__________________________________________________\n",
      "VALIDATION epoch 11                                                  \n",
      "LOSSES: 0.0241 (train), 0.0263 (val)\n",
      "OD segmentation (Dice Score): 0.8251 (train), 0.7683 (val)\n",
      "OC segmentation (Dice Score): 0.6648 (train), 0.6091 (val)\n",
      "vCDR error: 0.7852 (train), 0.3976 (val)\n",
      "__________________________________________________\n",
      "VALIDATION epoch 12                                                  \n",
      "LOSSES: 0.0205 (train), 0.0204 (val)\n",
      "OD segmentation (Dice Score): 0.8310 (train), 0.7964 (val)\n",
      "OC segmentation (Dice Score): 0.6720 (train), 0.8165 (val)\n",
      "vCDR error: 0.8110 (train), 0.1195 (val)\n",
      "__________________________________________________\n",
      "VALIDATION epoch 13                                                  \n",
      "LOSSES: 0.0174 (train), 0.0178 (val)\n",
      "OD segmentation (Dice Score): 0.8414 (train), 0.7825 (val)\n",
      "OC segmentation (Dice Score): 0.6784 (train), 0.8078 (val)\n",
      "vCDR error: 0.7701 (train), 0.1931 (val)\n",
      "__________________________________________________\n",
      "VALIDATION epoch 14                                                  \n",
      "LOSSES: 0.0151 (train), 0.0148 (val)\n",
      "OD segmentation (Dice Score): 0.8468 (train), 0.8240 (val)\n",
      "OC segmentation (Dice Score): 0.6851 (train), 0.8420 (val)\n",
      "vCDR error: 0.7495 (train), 0.0883 (val)\n",
      "Best validation AUC reached. Saved model weights.\n",
      "__________________________________________________\n",
      "VALIDATION epoch 15                                                  \n",
      "LOSSES: 0.0133 (train), 0.0146 (val)\n",
      "OD segmentation (Dice Score): 0.8527 (train), 0.7773 (val)\n",
      "OC segmentation (Dice Score): 0.6914 (train), 0.8128 (val)\n",
      "vCDR error: 0.8001 (train), 0.5041 (val)\n",
      "__________________________________________________\n",
      "VALIDATION epoch 16                                                  \n",
      "LOSSES: 0.0117 (train), 0.0138 (val)\n",
      "OD segmentation (Dice Score): 0.8605 (train), 0.7872 (val)\n",
      "OC segmentation (Dice Score): 0.7016 (train), 0.8331 (val)\n",
      "vCDR error: 0.7869 (train), 0.1009 (val)\n",
      "__________________________________________________\n",
      "VALIDATION epoch 17                                                  \n",
      "LOSSES: 0.0107 (train), 0.0122 (val)\n",
      "OD segmentation (Dice Score): 0.8630 (train), 0.7978 (val)\n",
      "OC segmentation (Dice Score): 0.7012 (train), 0.8533 (val)\n",
      "vCDR error: 0.7680 (train), 0.1034 (val)\n",
      "__________________________________________________\n",
      "VALIDATION epoch 18                                                  \n",
      "LOSSES: 0.0097 (train), 0.0116 (val)\n",
      "OD segmentation (Dice Score): 0.8669 (train), 0.7917 (val)\n",
      "OC segmentation (Dice Score): 0.7068 (train), 0.8393 (val)\n",
      "vCDR error: 0.8058 (train), 0.2036 (val)\n",
      "__________________________________________________\n",
      "VALIDATION epoch 19                                                  \n",
      "LOSSES: 0.0088 (train), 0.0113 (val)\n",
      "OD segmentation (Dice Score): 0.8725 (train), 0.7765 (val)\n",
      "OC segmentation (Dice Score): 0.7117 (train), 0.8286 (val)\n",
      "vCDR error: 0.8312 (train), 0.1506 (val)\n",
      "__________________________________________________\n",
      "VALIDATION epoch 20                                                  \n",
      "LOSSES: 0.0083 (train), 0.0097 (val)\n",
      "OD segmentation (Dice Score): 0.8694 (train), 0.8167 (val)\n",
      "OC segmentation (Dice Score): 0.7160 (train), 0.8142 (val)\n",
      "vCDR error: 0.8498 (train), 0.1001 (val)\n",
      "__________________________________________________\n",
      "VALIDATION epoch 21                                                  \n",
      "LOSSES: 0.0080 (train), 0.0103 (val)\n",
      "OD segmentation (Dice Score): 0.8677 (train), 0.7832 (val)\n",
      "OC segmentation (Dice Score): 0.7117 (train), 0.8348 (val)\n",
      "vCDR error: 0.8541 (train), 0.1551 (val)\n",
      "__________________________________________________\n",
      "VALIDATION epoch 22                                                  \n",
      "LOSSES: 0.0070 (train), 0.0085 (val)\n",
      "OD segmentation (Dice Score): 0.8807 (train), 0.8248 (val)\n",
      "OC segmentation (Dice Score): 0.7225 (train), 0.8454 (val)\n",
      "vCDR error: 0.8814 (train), 0.1015 (val)\n",
      "Best validation AUC reached. Saved model weights.\n",
      "__________________________________________________\n",
      "VALIDATION epoch 23                                                  \n",
      "LOSSES: 0.0066 (train), 0.0078 (val)\n",
      "OD segmentation (Dice Score): 0.8823 (train), 0.8498 (val)\n",
      "OC segmentation (Dice Score): 0.7273 (train), 0.8385 (val)\n",
      "vCDR error: 0.8874 (train), 0.1055 (val)\n",
      "Best validation AUC reached. Saved model weights.\n",
      "__________________________________________________\n",
      "VALIDATION epoch 24                                                  \n",
      "LOSSES: 0.0061 (train), 0.0090 (val)\n",
      "OD segmentation (Dice Score): 0.8862 (train), 0.7946 (val)\n",
      "OC segmentation (Dice Score): 0.7344 (train), 0.8406 (val)\n",
      "vCDR error: 0.9295 (train), 0.0886 (val)\n",
      "__________________________________________________\n",
      "VALIDATION epoch 25                                                  \n",
      "LOSSES: 0.0057 (train), 0.0114 (val)\n",
      "OD segmentation (Dice Score): 0.8897 (train), 0.7426 (val)\n",
      "OC segmentation (Dice Score): 0.7387 (train), 0.7514 (val)\n",
      "vCDR error: 0.9121 (train), 0.2715 (val)\n",
      "__________________________________________________\n",
      "VALIDATION epoch 26                                                  \n",
      "LOSSES: 0.0055 (train), 0.0085 (val)\n",
      "OD segmentation (Dice Score): 0.8911 (train), 0.8229 (val)\n",
      "OC segmentation (Dice Score): 0.7441 (train), 0.8232 (val)\n",
      "vCDR error: 0.9411 (train), 0.1522 (val)\n",
      "__________________________________________________\n",
      "VALIDATION epoch 27                                                  \n",
      "LOSSES: 0.0055 (train), 0.0097 (val)\n",
      "OD segmentation (Dice Score): 0.8844 (train), 0.8031 (val)\n",
      "OC segmentation (Dice Score): 0.7364 (train), 0.7679 (val)\n",
      "vCDR error: 0.9211 (train), 0.1534 (val)\n",
      "__________________________________________________\n",
      "VALIDATION epoch 28                                                  \n",
      "LOSSES: 0.0050 (train), 0.0075 (val)\n",
      "OD segmentation (Dice Score): 0.8933 (train), 0.8256 (val)\n",
      "OC segmentation (Dice Score): 0.7437 (train), 0.8468 (val)\n",
      "vCDR error: 0.9988 (train), 0.1010 (val)\n",
      "__________________________________________________\n",
      "VALIDATION epoch 29                                                  \n",
      "LOSSES: 0.0048 (train), 0.0086 (val)\n",
      "OD segmentation (Dice Score): 0.8950 (train), 0.7839 (val)\n",
      "OC segmentation (Dice Score): 0.7550 (train), 0.8421 (val)\n",
      "vCDR error: 0.9836 (train), 0.1214 (val)\n",
      "__________________________________________________\n",
      "VALIDATION epoch 30                                                  \n",
      "LOSSES: 0.0044 (train), 0.0083 (val)\n",
      "OD segmentation (Dice Score): 0.9009 (train), 0.7993 (val)\n",
      "OC segmentation (Dice Score): 0.7592 (train), 0.8405 (val)\n",
      "vCDR error: 0.9153 (train), 0.1565 (val)\n",
      "__________________________________________________\n",
      "VALIDATION epoch 31                                                  \n",
      "LOSSES: 0.0042 (train), 0.0074 (val)\n",
      "OD segmentation (Dice Score): 0.9030 (train), 0.8235 (val)\n",
      "OC segmentation (Dice Score): 0.7630 (train), 0.8437 (val)\n",
      "vCDR error: 1.0067 (train), 0.1419 (val)\n",
      "__________________________________________________\n",
      "VALIDATION epoch 32                                                  \n",
      "LOSSES: 0.0038 (train), 0.0070 (val)\n",
      "OD segmentation (Dice Score): 0.9108 (train), 0.8288 (val)\n",
      "OC segmentation (Dice Score): 0.7752 (train), 0.8519 (val)\n",
      "vCDR error: 1.0172 (train), 0.1210 (val)\n",
      "__________________________________________________\n",
      "VALIDATION epoch 33                                                  \n",
      "LOSSES: 0.0036 (train), 0.0083 (val)\n",
      "OD segmentation (Dice Score): 0.9136 (train), 0.8010 (val)\n",
      "OC segmentation (Dice Score): 0.7757 (train), 0.8498 (val)\n",
      "vCDR error: 1.0102 (train), 0.1273 (val)\n",
      "__________________________________________________\n",
      "VALIDATION epoch 34                                                  \n",
      "LOSSES: 0.0035 (train), 0.0084 (val)\n",
      "OD segmentation (Dice Score): 0.9144 (train), 0.8056 (val)\n",
      "OC segmentation (Dice Score): 0.7776 (train), 0.8487 (val)\n",
      "vCDR error: 0.9639 (train), 0.1004 (val)\n",
      "__________________________________________________\n",
      "VALIDATION epoch 35                                                  \n",
      "LOSSES: 0.0034 (train), 0.0083 (val)\n",
      "OD segmentation (Dice Score): 0.9153 (train), 0.8036 (val)\n",
      "OC segmentation (Dice Score): 0.7778 (train), 0.8525 (val)\n",
      "vCDR error: 0.9778 (train), 0.1126 (val)\n",
      "__________________________________________________\n",
      "VALIDATION epoch 36                                                  \n",
      "LOSSES: 0.0033 (train), 0.0067 (val)\n",
      "OD segmentation (Dice Score): 0.9164 (train), 0.8362 (val)\n",
      "OC segmentation (Dice Score): 0.7824 (train), 0.8564 (val)\n",
      "vCDR error: 0.9830 (train), 0.1085 (val)\n",
      "Best validation AUC reached. Saved model weights.\n",
      "__________________________________________________\n",
      "VALIDATION epoch 37                                                  \n",
      "LOSSES: 0.0031 (train), 0.0081 (val)\n",
      "OD segmentation (Dice Score): 0.9194 (train), 0.8076 (val)\n",
      "OC segmentation (Dice Score): 0.7868 (train), 0.8473 (val)\n",
      "vCDR error: 1.0167 (train), 0.1434 (val)\n",
      "__________________________________________________\n",
      "VALIDATION epoch 38                                                  \n",
      "LOSSES: 0.0028 (train), 0.0070 (val)\n",
      "OD segmentation (Dice Score): 0.9258 (train), 0.8465 (val)\n",
      "OC segmentation (Dice Score): 0.7911 (train), 0.8469 (val)\n",
      "vCDR error: 1.0796 (train), 0.0924 (val)\n",
      "Best validation AUC reached. Saved model weights.\n",
      "__________________________________________________\n",
      "VALIDATION epoch 39                                                  \n",
      "LOSSES: 0.0030 (train), 0.0082 (val)\n",
      "OD segmentation (Dice Score): 0.9216 (train), 0.8264 (val)\n",
      "OC segmentation (Dice Score): 0.7894 (train), 0.8499 (val)\n",
      "vCDR error: 1.0004 (train), 0.1101 (val)\n",
      "__________________________________________________\n",
      "VALIDATION epoch 40                                                  \n",
      "LOSSES: 0.0030 (train), 0.0093 (val)\n",
      "OD segmentation (Dice Score): 0.9214 (train), 0.7946 (val)\n",
      "OC segmentation (Dice Score): 0.7873 (train), 0.8345 (val)\n",
      "vCDR error: 0.9929 (train), 0.1277 (val)\n",
      "__________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define parameters\n",
    "nb_train_batches = len(train_loader)\n",
    "nb_val_batches = len(val_loader)\n",
    "nb_iter = 0\n",
    "best_val_auc = 0.\n",
    "iters = list(range(1, 10))\n",
    "val_losses = []\n",
    "train_losses = []\n",
    "train_accuracy=[]\n",
    "val_accuracy=[]\n",
    "\n",
    "\n",
    "while model.epoch < total_epoch:\n",
    "    # Accumulators\n",
    "    train_vCDRs, val_vCDRs = [], []\n",
    "    train_loss, val_loss = 0., 0.\n",
    "    train_dsc_od, val_dsc_od = 0., 0.\n",
    "    train_dsc_oc, val_dsc_oc = 0., 0.\n",
    "    train_vCDR_error, val_vCDR_error = 0., 0.\n",
    "    \n",
    "    ############\n",
    "    # TRAINING #\n",
    "    ############\n",
    "    model.train()\n",
    "    train_data = iter(train_loader)\n",
    "    for k in range(nb_train_batches):\n",
    "        # Loads data\n",
    "        imgs, seg_gts = train_data.next()\n",
    "        imgs, seg_gts = imgs.to(device), seg_gts.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        logits = model(imgs)\n",
    "        loss = seg_loss(logits, seg_gts)\n",
    " \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() / nb_train_batches\n",
    "        #for printing the loss curves\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Compute segmentation metric\n",
    "            pred_od = refine_seg((logits[:,0,:,:]>=0.5).type(torch.int8).cpu()).to(device)\n",
    "            #pred_od = refine_seg((logits[:,0,:,:]>=0.5).type(torch.int8).cpu())\n",
    "            pred_oc = refine_seg((logits[:,1,:,:]>=0.5).type(torch.int8).cpu()).to(device)\n",
    "            #pred_oc = refine_seg((logits[:,1,:,:]>=0.5).type(torch.int8).cpu())\n",
    "            gt_od = seg_gts[:,0,:,:].type(torch.int8)\n",
    "            gt_oc = seg_gts[:,1,:,:].type(torch.int8)\n",
    "            dsc_od = compute_dice_coef(pred_od, gt_od)\n",
    "            dsc_oc = compute_dice_coef(pred_oc, gt_oc)\n",
    "            train_dsc_od += dsc_od.item()/nb_train_batches\n",
    "            train_dsc_oc += dsc_oc.item()/nb_train_batches\n",
    "\n",
    "\n",
    "            # Compute and store vCDRs\n",
    "            vCDR_error, pred_vCDR, gt_vCDR = compute_vCDR_error(pred_od.cpu().numpy(), pred_oc.cpu().numpy(), gt_od.cpu().numpy(), gt_oc.cpu().numpy())\n",
    "            train_vCDRs += pred_vCDR.tolist()\n",
    "            train_vCDR_error += vCDR_error  / nb_train_batches\n",
    "            \n",
    "        # Increase iterations\n",
    "        nb_iter += 1\n",
    "        \n",
    "        # Std out\n",
    "        print('Epoch {}, iter {}/{}, loss {:.6f}'.format(model.epoch+1, k+1, nb_train_batches, loss.item()) + ' '*20, \n",
    "              end='\\r')\n",
    "    \n",
    "    ##############\n",
    "    # VALIDATION #\n",
    "    ##############\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_data = iter(val_loader)\n",
    "        for k in range(nb_val_batches):\n",
    "            # Loads data\n",
    "            imgs, seg_gts = val_data.next()\n",
    "            imgs, seg_gts = imgs.to(device), seg_gts.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            logits = model(imgs)\n",
    "            val_loss += seg_loss(logits, seg_gts).item() / nb_val_batches\n",
    "            \n",
    "            val_losses.append(val_loss)\n",
    "\n",
    "            # Std out\n",
    "            print('Validation iter {}/{}'.format(k+1, nb_val_batches) + ' '*50, \n",
    "                  end='\\r')\n",
    "            \n",
    "            # Compute segmentation metric\n",
    "            pred_od = refine_seg((logits[:,0,:,:]>=0.5).type(torch.int8).cpu()).to(device)\n",
    "            pred_oc = refine_seg((logits[:,1,:,:]>=0.5).type(torch.int8).cpu()).to(device)\n",
    "            gt_od = seg_gts[:,0,:,:].type(torch.int8)\n",
    "            gt_oc = seg_gts[:,1,:,:].type(torch.int8)\n",
    "            dsc_od = compute_dice_coef(pred_od, gt_od)\n",
    "            dsc_oc = compute_dice_coef(pred_oc, gt_oc)\n",
    "            val_dsc_od += dsc_od.item()/nb_val_batches\n",
    "            val_dsc_oc += dsc_oc.item()/nb_val_batches\n",
    "            \n",
    "        \n",
    "            vCDR_error, pred_vCDR, gt_vCDR = compute_vCDR_error(pred_od.cpu().numpy(), pred_oc.cpu().numpy(), gt_od.cpu().numpy(), gt_oc.cpu().numpy())\n",
    "            val_vCDRs += pred_vCDR.tolist()\n",
    "            val_vCDR_error += vCDR_error / nb_val_batches\n",
    "    print('VALIDATION epoch {}'.format(model.epoch+1)+' '*50)\n",
    "    print('LOSSES: {:.4f} (train), {:.4f} (val)'.format(train_loss, val_loss))\n",
    "    print('OD segmentation (Dice Score): {:.4f} (train), {:.4f} (val)'.format(train_dsc_od, val_dsc_od))\n",
    "    print('OC segmentation (Dice Score): {:.4f} (train), {:.4f} (val)'.format(train_dsc_oc, val_dsc_oc))\n",
    "    print('vCDR error: {:.4f} (train), {:.4f} (val)'.format(train_vCDR_error, val_vCDR_error))\n",
    "    # Save model if best validation AUC is reached\n",
    "    if val_dsc_od + val_dsc_oc > best_val_auc:\n",
    "        torch.save(model.state_dict(), '/kaggle/working/best_seg.pth')\n",
    "        best_val_auc = val_dsc_od + val_dsc_oc\n",
    "        print('Best validation AUC reached. Saved model weights.')\n",
    "    print('_'*50)\n",
    "        \n",
    "    # End of epoch\n",
    "    model.epoch += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a79dd7",
   "metadata": {
    "papermill": {
     "duration": 0.771667,
     "end_time": "2022-06-26T16:22:21.736010",
     "exception": false,
     "start_time": "2022-06-26T16:22:20.964343",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Vizualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2b020fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T16:22:23.713203Z",
     "iopub.status.busy": "2022-06-26T16:22:23.712771Z",
     "iopub.status.idle": "2022-06-26T16:22:23.869178Z",
     "shell.execute_reply": "2022-06-26T16:22:23.867955Z"
    },
    "papermill": {
     "duration": 1.196942,
     "end_time": "2022-06-26T16:22:23.871530",
     "exception": false,
     "start_time": "2022-06-26T16:22:22.674588",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "images_path = \"../input/glaucoma-datasets/ORIGA/Images_Square\"\n",
    "masks_path = \"../input/glaucoma-datasets/ORIGA/Masks_Square\"\n",
    "image_filenames = []\n",
    "for path in os.listdir(images_path):\n",
    "    image_filenames.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89451c21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T16:22:25.379105Z",
     "iopub.status.busy": "2022-06-26T16:22:25.378744Z",
     "iopub.status.idle": "2022-06-26T16:22:25.389209Z",
     "shell.execute_reply": "2022-06-26T16:22:25.388324Z"
    },
    "papermill": {
     "duration": 0.740505,
     "end_time": "2022-06-26T16:22:25.391166",
     "exception": false,
     "start_time": "2022-06-26T16:22:24.650661",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_size = (256, 256)\n",
    "def get_seg_img(filename):\n",
    "    img = np.array(Image.open(os.path.join(images_path, filename)).convert('RGB'))\n",
    "    #sample_img = img\n",
    "    img = transforms.functional.to_tensor(img)\n",
    "    img = transforms.functional.resize(img, output_size, interpolation=Image.BILINEAR)\n",
    "    filename_mask = filename[:-3] + \"png\"\n",
    "    mask = np.array(Image.open(os.path.join(masks_path, filename_mask), mode='r'))\n",
    "    od = (mask==1.).astype(np.float32)\n",
    "    oc = (mask==2.).astype(np.float32)\n",
    "    od = torch.from_numpy(od[None,:,:])\n",
    "    oc = torch.from_numpy(oc[None,:,:])\n",
    "    od = transforms.functional.resize(od, output_size, interpolation=Image.NEAREST)\n",
    "    oc = transforms.functional.resize(oc, output_size, interpolation=Image.NEAREST)\n",
    "    seg = torch.cat([od, oc], dim=0)\n",
    "\n",
    "    \n",
    "    return img, seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d148bfbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T16:22:26.894667Z",
     "iopub.status.busy": "2022-06-26T16:22:26.894323Z",
     "iopub.status.idle": "2022-06-26T16:22:26.903908Z",
     "shell.execute_reply": "2022-06-26T16:22:26.902940Z"
    },
    "papermill": {
     "duration": 0.737103,
     "end_time": "2022-06-26T16:22:26.905903",
     "exception": false,
     "start_time": "2022-06-26T16:22:26.168800",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_preds(num):\n",
    "    filename = image_filenames[num]\n",
    "    val_mask = resize(np.array(Image.open(os.path.join(masks_path, filename[:-3] + \"png\"), mode='r')), (256, 256))\n",
    "    img, gt_seg = get_seg_img(filename)\n",
    "    sample_img = img.numpy()\n",
    "    sample_mask = gt_seg.numpy()\n",
    "    img = torch.unsqueeze(img, 0).to(device)\n",
    "    gt_seg = torch.unsqueeze(gt_seg, 0).to(device)\n",
    "\n",
    "    logits = model(img)\n",
    "    pred_od = refine_seg((logits[:,0,:,:]>=0.5).type(torch.int8).cpu())\n",
    "    pred_oc = refine_seg((logits[:,1,:,:]>=0.5).type(torch.int8).cpu())\n",
    "    gt_od = gt_seg[:,0,:,:].type(torch.int8)\n",
    "    gt_oc = gt_seg[:,1,:,:].type(torch.int8)\n",
    "    return sample_img, sample_mask, pred_od, pred_oc, gt_od, gt_oc, val_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ddb8432",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T16:22:28.665553Z",
     "iopub.status.busy": "2022-06-26T16:22:28.665205Z",
     "iopub.status.idle": "2022-06-26T16:22:28.670360Z",
     "shell.execute_reply": "2022-06-26T16:22:28.669362Z"
    },
    "papermill": {
     "duration": 0.754867,
     "end_time": "2022-06-26T16:22:28.672317",
     "exception": false,
     "start_time": "2022-06-26T16:22:27.917450",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from skimage.transform import resize\n",
    "# sample_img, sample_mask, pred_od, pred_oc, gt_od, gt_oc, val_mask = get_preds(14)\n",
    "# f, axarr = plt.subplots(1, 3, squeeze=False)\n",
    "# # print(compute_dice_coef(pred_oc, gt_oc))\n",
    "# # print(compute_dice_coef(pred_od, gt_od))\n",
    "\n",
    "# input_img = np.swapaxes(np.swapaxes(sample_img, 0, 2), 0, 1)\n",
    "# gt_mask = np.swapaxes(np.swapaxes(sample_mask, 0, 2), 0, 1)\n",
    "# gt_mask[:, :, 0][gt_mask[:, :, 0] > 0] = 2\n",
    "# output_mask =  gt_mask[:, :, 0] + gt_mask[:, :, 1]\n",
    "# print(gt_mask.shape, output_mask.shape)\n",
    "# print(np.max(output_mask))\n",
    "# pred_od_mask = pred_od.numpy().reshape(256, 256) + (2 * pred_oc.numpy().reshape(256, 256))\n",
    "\n",
    "# axarr[0][0].imshow(input_img)\n",
    "# axarr[0][1].imshow(val_mask)\n",
    "# axarr[0][2].imshow(pred_od_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2149d873",
   "metadata": {
    "papermill": {
     "duration": 0.772773,
     "end_time": "2022-06-26T16:22:30.169119",
     "exception": false,
     "start_time": "2022-06-26T16:22:29.396346",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d76f0eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T16:22:31.664527Z",
     "iopub.status.busy": "2022-06-26T16:22:31.663829Z",
     "iopub.status.idle": "2022-06-26T16:22:31.676923Z",
     "shell.execute_reply": "2022-06-26T16:22:31.675883Z"
    },
    "papermill": {
     "duration": 0.740292,
     "end_time": "2022-06-26T16:22:31.682037",
     "exception": false,
     "start_time": "2022-06-26T16:22:30.941745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='best_seg.pth' target='_blank'>best_seg.pth</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/best_seg.pth"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd /kaggle/working\n",
    "from IPython.display import FileLink\n",
    "FileLink(r'best_seg.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5034.196836,
   "end_time": "2022-06-26T16:22:35.398321",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-06-26T14:58:41.201485",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
